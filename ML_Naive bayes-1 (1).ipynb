{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "847adbb7-db76-4977-981e-bb4bb638709c",
   "metadata": {},
   "source": [
    "Q1. What is Bayes' theorem?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cd065e-f3c9-4607-a19d-30f13d51dd2b",
   "metadata": {},
   "source": [
    "#Answer\n",
    "\n",
    "Bayes' theorem is a fundamental concept in probability theory and statistics. It provides a way to calculate the probability of a hypothesis or event based on new evidence or observations. It is named after Thomas Bayes, an English statistician and Presbyterian minister, who developed the theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d768ab2e-88b4-43b3-a1dd-6c72edbb4923",
   "metadata": {},
   "source": [
    "                      -------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491180f2-5135-481c-9aa5-c7f7f6e92a5f",
   "metadata": {},
   "source": [
    "Q2. What is the formula for Bayes' theorem?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c8edb9-4e1e-477c-a364-b94ab71036a4",
   "metadata": {},
   "source": [
    "#Answer\n",
    "\n",
    "The formula for Bayes' theorem is as follows:\n",
    "\n",
    "P(A|B) = (P(B|A) * P(A)) / P(B)\n",
    "\n",
    "Where:\n",
    "\n",
    "P(A|B) is the probability of event A occurring given that event B has occurred (posterior probability).\n",
    "\n",
    "P(B|A) is the probability of event B occurring given that event A has occurred (likelihood).\n",
    "\n",
    "P(A) is the probability of event A occurring before considering any evidence (prior probability).\n",
    "\n",
    "P(B) is the probability of event B occurring before considering any evidence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e7fe27-1fe2-442b-9990-ddf2b4958328",
   "metadata": {},
   "source": [
    "                      -------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acec684-dfcf-48b9-919d-91939ae4fe94",
   "metadata": {},
   "source": [
    "Q3. How is Bayes' theorem used in practice?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772d565c-385c-439b-9285-61ed94caf9fa",
   "metadata": {},
   "source": [
    "#Answer\n",
    "\n",
    "Bayes' theorem is widely used in various fields, including machine learning, natural language processing, medical diagnosis, spam filtering, and more. In practice, it is used to update beliefs or probabilities about an event or hypothesis based on new data or evidence. It is especially useful when dealing with uncertain or incomplete information.\n",
    "\n",
    "For example, in machine learning, Bayes' theorem is used in Naive Bayes classifiers for text classification tasks, spam detection, sentiment analysis, and more. It also serves as the basis for Bayesian inference, which is a powerful statistical approach for estimating parameters in models and making predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab68aa9b-06e7-48ba-9454-ab662e3c7fc2",
   "metadata": {},
   "source": [
    "                      -------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603d8454-0f91-4c58-9047-9330eaa2c9b0",
   "metadata": {},
   "source": [
    "Q4. What is the relationship between Bayes' theorem and conditional probability?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cc33b3-63e6-4865-85f7-d4d8babbb1e0",
   "metadata": {},
   "source": [
    "#Answer\n",
    "\n",
    "Bayes' theorem is closely related to conditional probability. The conditional probability P(A|B) is the probability of event A occurring given that event B has occurred. Bayes' theorem provides a way to calculate this conditional probability by incorporating the prior probability P(A), the likelihood P(B|A), and the overall probability of event B, P(B).\n",
    "\n",
    "In essence, Bayes' theorem allows us to update our initial beliefs (prior probabilities) about an event based on new evidence (likelihood) to obtain revised or updated probabilities (posterior probabilities) considering all available information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefbaf43-6ff9-49ad-b189-2a56c6f188e8",
   "metadata": {},
   "source": [
    "                      -------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83dbde1-120b-428e-9820-73b17987c381",
   "metadata": {},
   "source": [
    "Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c6469c-811c-4261-854e-d172b6171204",
   "metadata": {},
   "source": [
    "#Answer\n",
    "\n",
    "The choice of the type of Naive Bayes classifier depends on the nature of the data and the specific problem you are trying to solve. The three main types of Naive Bayes classifiers are:\n",
    "\n",
    "Gaussian Naive Bayes: This classifier is used when the features follow a Gaussian (normal) distribution. It assumes that each class's features are normally distributed and estimates the mean and standard deviation for each class.\n",
    "\n",
    "Multinomial Naive Bayes: This classifier is commonly used for discrete features, such as word counts in text classification problems. It assumes that the features are generated from a multinomial distribution.\n",
    "\n",
    "Bernoulli Naive Bayes: This classifier is used for binary features, where each feature can take only two values (0 or 1). It assumes that each feature is generated from a Bernoulli distribution.\n",
    "\n",
    "To choose the appropriate type of Naive Bayes classifier, consider the type of features in your dataset. If the features are continuous and follow a Gaussian distribution, use Gaussian Naive Bayes. For discrete features, such as word frequencies, use Multinomial Naive Bayes. If you have binary features, opt for Bernoulli Naive Bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd56842-96dd-463e-9a53-abe5f7acc2c6",
   "metadata": {},
   "source": [
    "                       -------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f880f864-eebc-40da-a43b-2320566cd015",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6. Assignment:\n",
    "\n",
    "You have a dataset with two features, X1 and X2, and two possible classes, A and B. You want to use Naive\n",
    "Bayes to classify a new instance with features X1 = 3 and X2 = 4. The following table shows the frequency of\n",
    "each feature value for each class:\n",
    "\n",
    "Class X1=1 X1=2 X1=3 X2=1 X2=2 X2=3 X2=4\n",
    "\n",
    "   A   3    3    4    4     3   3   3\n",
    "\n",
    "   B   2    2    1    2     2   2   3\n",
    "\n",
    "Assuming equal prior probabilities for each class, which class would Naive Bayes predict the new instance\n",
    "to belong to?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5ec4f9-dded-413f-b97e-d4ac1759a65a",
   "metadata": {},
   "source": [
    "#Answer\n",
    "\n",
    "Calculating the probabilities for each class using Naive Bayes:\n",
    "\n",
    "Step 1: Calculate the prior probabilities P(A) and P(B). Since the prior probabilities are assumed to be equal, P(A) = P(B) = 0.5.\n",
    "\n",
    "Step 2: Calculate the likelihood probabilities P(X1=3|A) and P(X2=4|A) for Class A:\n",
    "\n",
    "P(X1=3|A) = 4/10 = 0.4\n",
    "\n",
    "P(X2=4|A) = 3/10 = 0.3\n",
    "\n",
    "Step 3: Calculate the likelihood probabilities P(X1=3|B) and P(X2=4|B) for Class B:\n",
    "\n",
    "P(X1=3|B) = 1/7 ≈ 0.1429\n",
    "\n",
    "P(X2=4|B) = 3/7 ≈ 0.4286\n",
    "\n",
    "Step 4: Calculate the joint likelihood probabilities for each class:\n",
    "\n",
    "P(X1=3, X2=4|A) = P(X1=3|A) * P(X2=4|A) = 0.4 * 0.3 = 0.12\n",
    "\n",
    "P(X1=3, X2=4|B) = P(X1=3|B) * P(X2=4|B) = 0.1429 * 0.4286 ≈ 0.0612\n",
    "\n",
    "Step 5: Calculate the evidence P(X1=3, X2=4) by summing the joint likelihood probabilities for each class:\n",
    "\n",
    "P(X1=3, X2=4) = P(X1=3, X2=4|A) + P(X1=3, X2=4|B) ≈ 0.12 + 0.0612 ≈ 0.1812\n",
    "\n",
    "Step 6: Calculate the posterior probabilities P(A|X1=3, X2=4) and P(B|X1=3, X2=4) using Bayes' theorem:\n",
    "\n",
    "P(A|X1=3, X2=4) = P(X1=3, X2=4|A) * P(A) / P(X1=3, X2=4) ≈ 0.12 * 0.5 / 0.1812 ≈ 0.3316\n",
    "\n",
    "P(B|X1=3, X2=4) = P(X1=3, X2=4|B) * P(B) / P(X1=3, X2=4) ≈ 0.0612 * 0.5 / 0.1812 ≈ 0.1684\n",
    "\n",
    "Since P(A|X1=3, X2=4) > P(B|X1=3, X2=4), the Naive Bayes classifier would predict that the new instance with features X1=3 and X2=4 belongs to Class A."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c195c9bd-aba6-49ad-a195-6b541eb54fb2",
   "metadata": {},
   "source": [
    "                        -------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
